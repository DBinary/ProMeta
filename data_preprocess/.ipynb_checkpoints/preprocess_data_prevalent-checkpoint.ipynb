{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b28100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776ced91",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_num = 500\n",
    "max_num = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3be1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '../out/'\n",
    "data_dir = '../../Prophet/data/'\n",
    "output_dir = '../out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 输入文件\n",
    "term2caseids_path = os.path.join(pkl_dir, 'term2caseids.pkl')\n",
    "term2casedates_path = os.path.join(pkl_dir, 'term2casedates.pkl')\n",
    "term2controlids_path = os.path.join(pkl_dir, 'term2controlids.pkl')\n",
    "proteomics_data_path = os.path.join(data_dir, 'preprocessed_proteomics_data.csv')\n",
    "\n",
    "# 输出文件\n",
    "output_date_matrix_path = os.path.join(output_dir, f'label_date_matrix_{min_num}_{max_num}.npy')\n",
    "output_mask_matrix_path = os.path.join(output_dir, f'label_mask_matrix_{min_num}_{max_num}.npy')\n",
    "\n",
    "# --- 2. 加载预处理好的数据 ---\n",
    "print(\"正在加载预处理好的 .pkl 文件...\")\n",
    "with open(term2caseids_path, 'rb') as f:\n",
    "    term2caseids = pkl.load(f)\n",
    "with open(term2casedates_path, 'rb') as f:\n",
    "    term2casedates = pkl.load(f)\n",
    "with open(term2controlids_path, 'rb') as f:\n",
    "    term2controlids = pkl.load(f)\n",
    "\n",
    "# 加载蛋白质组学数据以获取完整的参与者列表和顺序\n",
    "print(\"正在加载参与者列表...\")\n",
    "proteomics_df = pd.read_csv(proteomics_data_path)\n",
    "\n",
    "# 生成标签矩阵\n",
    "eid2idx = {eid: idx for idx, eid in enumerate(proteomics_df.EID.values.astype(str))}\n",
    "disease_list = [term for term in term2caseids if min_num <= len(term2caseids[term]) <= max_num]\n",
    "print(f\"找到 {len(disease_list)} 种合乎规定的疾病。\")\n",
    "label_date_matrix = np.full((len(proteomics_df), len(disease_list)), np.datetime64('NaT'), dtype='datetime64[D]')\n",
    "label_mask_matrix = np.ones((len(proteomics_df), len(disease_list)), dtype=int)\n",
    "for idx, term in enumerate(disease_list):\n",
    "    case_eids = term2caseids[term]\n",
    "    control_eids = term2controlids[term]\n",
    "    label_date_matrix[[eid2idx[eid] for eid in case_eids], idx] = term2casedates[term]\n",
    "    label_mask_matrix[[eid2idx[eid] for eid in case_eids], idx] = 0\n",
    "    label_mask_matrix[[eid2idx[eid] for eid in control_eids], idx] = 0\n",
    "np.save(output_date_matrix_path, label_date_matrix)\n",
    "np.save(output_mask_matrix_path, label_mask_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f4d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomics_date = pd.read_csv('/home/dataset-assist-0/yaosen/lihan/ght/Prophet-Meta-temp/Prophet/data/proteomics_test_date.csv')\n",
    "proteomics_date['proteomics_test_date'] = pd.to_datetime(proteomics_date['proteomics_test_date'])\n",
    "id2proteindates = dict(zip(proteomics_date['EID'].astype(str), proteomics_date['proteomics_test_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94458838",
   "metadata": {},
   "outputs": [],
   "source": [
    "term2pre_cases = {}\n",
    "term2pre_controls = {}\n",
    "\n",
    "term2inc_cases = {}\n",
    "term2inc_controls = {}\n",
    "\n",
    "for term in term2caseids:\n",
    "    case_eids = term2caseids[term]\n",
    "    control_eids = term2controlids[term]\n",
    "    pre_cases = []\n",
    "    pre_controls = []\n",
    "    inc_cases = []\n",
    "    inc_controls = []\n",
    "    for i,eid in enumerate(case_eids):\n",
    "        date = term2casedates[term][i]\n",
    "        if date < id2proteindates[eid]:\n",
    "            pre_cases.append(eid)\n",
    "        else:\n",
    "            inc_cases.append(eid)\n",
    "    # 对于controls，pre_controls需要去掉inc_cases中的eid, inc_controls同理，不需要考虑时间\n",
    "    for eid in control_eids:\n",
    "        if eid not in inc_cases:\n",
    "            pre_controls.append(eid)\n",
    "        if eid not in pre_cases:\n",
    "            inc_controls.append(eid)\n",
    "    term2pre_cases[term] = pre_cases\n",
    "    term2pre_controls[term] = pre_controls\n",
    "    term2inc_cases[term] = inc_cases\n",
    "    term2inc_controls[term] = inc_controls\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c29e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these files:\n",
    "with open(os.path.join(pkl_dir, 'term2pre_cases.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2pre_cases, f)\n",
    "with open(os.path.join(pkl_dir, 'term2pre_controls.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2pre_controls, f)\n",
    "with open(os.path.join(pkl_dir, 'term2inc_cases.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2inc_cases, f)\n",
    "with open(os.path.join(pkl_dir, 'term2inc_controls.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2inc_controls, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e9f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files:\n",
    "with open(os.path.join(pkl_dir, 'term2pre_cases.pkl'), 'rb') as f:\n",
    "    term2pre_cases = pkl.load(f)\n",
    "with open(os.path.join(pkl_dir, 'term2pre_controls.pkl'), 'rb') as f:\n",
    "    term2pre_controls = pkl.load(f)\n",
    "with open(os.path.join(pkl_dir, 'term2inc_cases.pkl'), 'rb') as f:\n",
    "    term2inc_cases = pkl.load(f)\n",
    "with open(os.path.join(pkl_dir, 'term2inc_controls.pkl'), 'rb') as f:\n",
    "    term2inc_controls = pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6fe617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dataset-assist-0/yaosen/lihan/ght/Prophet-Meta-temp/data/scripts\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ded9b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "eids = list(id2proteindates.keys())\n",
    "# split eids into train valid and test sets with ratio of 8:1:1:\n",
    "eids = np.random.permutation(eids)\n",
    "train_eids = list(eids)[:int(0.8*len(eids))]\n",
    "valid_eids = list(eids)[int(0.8*len(eids)):int(0.9*len(eids))]\n",
    "test_eids = list(eids)[int(0.9*len(eids)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "102461c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(907, 1219)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pre_terms = [term for term in term2pre_cases if 1000 > len(term2pre_cases[term]) > 50 and len(term2pre_controls[term]) > 50]\n",
    "valid_case_terms = [term for term in term2inc_cases if 1000 > len(term2inc_cases[term]) > 50 and len(term2inc_controls[term]) > 50]\n",
    "len(valid_pre_terms), len(valid_case_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a89baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "term2pre_cases_train, term2pre_controls_train = {}, {}\n",
    "term2pre_cases_valid, term2pre_controls_valid = {}, {}\n",
    "term2pre_cases_test, term2pre_controls_test = {}, {}\n",
    "\n",
    "for term in np.random.permutation(valid_pre_terms):\n",
    "    case_eids = term2pre_cases[term]\n",
    "    control_eids = term2pre_controls[term]\n",
    "    overlap_cases = np.intersect1d(test_eids, case_eids)\n",
    "    overlap_controls = np.intersect1d(test_eids, control_eids)\n",
    "    if len(overlap_cases) > 50 and len(overlap_controls) > len(overlap_cases):\n",
    "        term2pre_cases_test[term] = overlap_cases\n",
    "        term2pre_controls_test[term] = overlap_controls\n",
    "    if len(term2pre_cases_test) > 0.1*len(valid_pre_terms):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ff929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in np.random.permutation(valid_pre_terms):\n",
    "    if term in term2pre_cases_test:\n",
    "        continue\n",
    "    case_eids = term2pre_cases[term]\n",
    "    control_eids = term2pre_controls[term]\n",
    "    overlap_cases = np.intersect1d(valid_eids, case_eids)\n",
    "    overlap_controls = np.intersect1d(valid_eids, control_eids)\n",
    "    if len(overlap_cases) > 50 and len(overlap_controls) > len(overlap_cases):\n",
    "        term2pre_cases_valid[term] = overlap_cases\n",
    "        term2pre_controls_valid[term] = overlap_controls\n",
    "    if len(term2pre_cases_valid) > 0.1*len(valid_pre_terms):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eaa327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in np.random.permutation(valid_pre_terms):\n",
    "    if term in term2pre_cases_test or term in term2pre_cases_valid:\n",
    "        continue\n",
    "    case_eids = term2pre_cases[term]\n",
    "    control_eids = term2pre_controls[term]\n",
    "    overlap_cases = np.intersect1d(train_eids, case_eids)\n",
    "    overlap_controls = np.intersect1d(train_eids, control_eids)\n",
    "    if len(overlap_cases) > 32 and len(overlap_controls) > len(overlap_cases):\n",
    "        term2pre_cases_train[term] = overlap_cases\n",
    "        term2pre_controls_train[term] = overlap_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7d2789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788, 28, 91)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(term2pre_cases_train),len(term2pre_cases_valid),len(term2pre_cases_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bccec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 8 terms from train/valid set due to high Jaccard overlap (>0.75) with test sets.\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.75\n",
    "def jaccard(a, b):\n",
    "    a, b = set(a), set(b)\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    return len(a & b) / len(a | b)\n",
    "\n",
    "removed = []\n",
    "# iterate over a static list of test terms to avoid modifying during iteration\n",
    "for term in list(term2pre_cases_test.keys()):\n",
    "    test_set = set(term2pre_cases[term])\n",
    "    removed_flag = False\n",
    "    # check against training terms\n",
    "    for other_term in term2pre_cases_train.copy():\n",
    "        other_cases = term2pre_cases[other_term]\n",
    "        j = jaccard(test_set, other_cases)\n",
    "        if j > threshold:\n",
    "            removed.append((term, 'train', other_term, j))\n",
    "            term2pre_cases_train.pop(other_term, None)\n",
    "            term2pre_controls_train.pop(other_term, None)\n",
    "            removed_flag = True\n",
    "    # check against validation terms\n",
    "    for other_term in term2pre_cases_valid.copy():\n",
    "        other_cases = term2pre_cases[other_term]\n",
    "        j = jaccard(test_set, other_cases)\n",
    "        if j > threshold:\n",
    "            removed.append((term, 'valid', other_term, j))\n",
    "            term2pre_cases_valid.pop(other_term, None)\n",
    "            term2pre_controls_valid.pop(other_term, None)\n",
    "\n",
    "print(f\"Removed {len(removed)} terms from train/valid set due to high Jaccard overlap (>{threshold}) with test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3173e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2 terms from train set due to high Jaccard overlap (>0.75) with test sets.\n"
     ]
    }
   ],
   "source": [
    "removed = []\n",
    "# iterate over a static list of test terms to avoid modifying during iteration\n",
    "for term in list(term2pre_cases_valid.keys()):\n",
    "    valid_set = set(term2pre_cases[term])\n",
    "    for other_term in term2pre_cases_train.copy():\n",
    "        other_cases = term2pre_cases[other_term]\n",
    "        j = jaccard(valid_set, other_cases)\n",
    "        if j > threshold:\n",
    "            removed.append((term, 'valid', other_term, j))\n",
    "            term2pre_cases_train.pop(other_term, None)\n",
    "            term2pre_controls_train.pop(other_term, None)\n",
    "\n",
    "print(f\"Removed {len(removed)} terms from train set due to high Jaccard overlap (>{threshold}) with test sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78107407",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pkl_dir, 'term2pre_cases_train.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2pre_cases_train, f)\n",
    "with open(os.path.join(pkl_dir, 'term2pre_cases_valid.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2pre_caases_valid, f)\n",
    "with open(os.path.join(pkl_dir, 'term2pre_cases_test.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2pre_cases_test, f)\n",
    "    \n",
    "with open(os.path.join(pkl_dir, 'term2pre_controls_train.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2pre_controls_train, f)\n",
    "with open(os.path.join(pkl_dir, 'term2pre_controls_valid.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2pre_controls_valid, f)\n",
    "with open(os.path.join(pkl_dir, 'term2pre_controls_test.pkl'), 'wb') as f:\n",
    "    pkl.dump(term2pre_controls_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f399814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(783, 23, 91)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(term2pre_cases_train),len(term2pre_cases_valid),len(term2pre_cases_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683bd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c61246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
